name: 📄 문서수 수집 크론 (Document Count Collection)

on:
  schedule:
    # ✅ 안정성 우선: 15분마다 실행 (Search API 복구 고려)
    # miner.yml: */10 * * * * (0, 10, 20, 30, ...)
    # fill-docs.yml: */15 * * * * (0, 15, 30, 45) - 충분한 간격
    - cron: '*/10 * * * *'
  workflow_dispatch: # 수동 실행 가능

jobs:
  fill_docs:
    runs-on: ubuntu-latest
    timeout-minutes: 6  # 3.5분 루프 + 여유
    concurrency:
      # 문서수 수집 전용 그룹 (키워드 확장과 독립 실행)
      group: document-fill-cron
      cancel-in-progress: false
    
    steps:
      - name: 📄 문서수 수집 시작
        id: fill_docs
        run: |
          set -e  # 에러 시 즉시 중단
          
          # 환경 변수 검증
          if [ -z "${{ secrets.PROD_URL }}" ] || [ -z "${{ secrets.CRON_SECRET }}" ]; then
            echo "❌ ERROR: PROD_URL or CRON_SECRET is not set in GitHub Secrets."
            exit 1
          fi
          
          START_TIME=$(date +%s)
          echo "📄🚀 Starting ULTRA document count collection at $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
          echo "🔗 Target: ${{ secrets.PROD_URL }}/api/miner/execute"

          # ═══════════════════════════════════════════════════════════════════════
          # 🚀 초고성능: SEARCH API 30개 키 최대 활용
          # ═══════════════════════════════════════════════════════════════════════
          # 
          # 📊 SEARCH API 활용 전략:
          # - 30개 키 × 일일 25,000회 = 750,000회 가능
          # - 키워드당 4개 API 호출 (blog, cafe, web, news)
          # - 일일 187,500개 키워드 문서수 수집 가능
          #
          # ⚡ 최적화 수치 (GitHub Actions 5분 제한 준수):
          # - 크론 주기: 5분마다 (하루 288회)
          # - 루프 시간: 3.5분 (210초)
          # - 호출 간격: 10초 (루프당 21회 API 호출)
          # - 배치 크기: 500개 (동시성의 5배)
          # - 동시성: 100개 (30개 키 × 3.3)
          #
          # 📈 예상 처리량:
          # - 크론당: 21회 × 500개 = 10,500개 키워드
          # - 일일: 288회 × 10,500 = 3,024,000개 (이론상)
          # - 실제 (중복/실패 고려): 25만~35만개/일
          # ═══════════════════════════════════════════════════════════════════════
          
          RUN_FOR_SECONDS=210  # 3.5분간 실행
          INTERVAL_SECONDS=5   # 5초마다 API 호출
          END_TIME=$((START_TIME + RUN_FOR_SECONDS))

          # ✅ 안정성 최우선 파라미터 (점진적 증가 계획)
          # - fillBatch=100 => 100 키워드/실행 (부담 최소화)
          # - fillConcurrency=10 => 10 동시성 (SEARCH 30개의 1/3만 사용)
          # - maxRunMs=55000 => Vercel 60초 제한 고려
          # 80%+ 성공률 목표, 안정화 후 점진적 증가
          QUERY="task=fill_docs&fillBatch=200&fillConcurrency=25&maxRunMs=55000"

          TOTAL_OK=0
          TOTAL_FAIL=0
          TOTAL_KEYWORDS=0

          while [ $(date +%s) -lt $END_TIME ]; do
            echo ""
            echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
            echo "📡 API 호출: ${{ secrets.PROD_URL }}/api/miner/execute?$QUERY"
            echo "⏰ 남은 시간: $((END_TIME - $(date +%s)))초"

            # 재시도 로직
            MAX_RETRIES=2
            RETRY_COUNT=0
            SUCCESS=false

            while [ $RETRY_COUNT -lt $MAX_RETRIES ] && [ "$SUCCESS" = "false" ]; do
              RESPONSE=$(curl -X GET "${{ secrets.PROD_URL }}/api/miner/execute?$QUERY" \
                -H "CRON_SECRET: ${{ secrets.CRON_SECRET }}" \
                -w "\n%{http_code}" \
                --max-time 75 \
                --silent \
                --show-error) || true

              HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
              BODY=$(echo "$RESPONSE" | sed '$d')

              if [ "$HTTP_CODE" = "200" ]; then
                SUCCESS=true
                TOTAL_OK=$((TOTAL_OK + 1))
                echo "✅ HTTP $HTTP_CODE - 성공"
                
                # JSON 응답 파싱 (jq가 있으면)
                if command -v jq &> /dev/null; then
                  echo "$BODY" | jq '.' || echo "$BODY"
                  # 처리된 키워드 수 추출 (응답에 포함된 경우)
                  KEYWORDS_PROCESSED=$(echo "$BODY" | jq -r '.fillDocs?.processed // 0' 2>/dev/null || echo "0")
                  if [ "$KEYWORDS_PROCESSED" != "0" ] && [ "$KEYWORDS_PROCESSED" != "null" ]; then
                    TOTAL_KEYWORDS=$((TOTAL_KEYWORDS + KEYWORDS_PROCESSED))
                    echo "📊 이번 배치 처리: ${KEYWORDS_PROCESSED}개 키워드"
                  fi
                else
                  echo "$BODY"
                fi
              else
                RETRY_COUNT=$((RETRY_COUNT + 1))
                echo "⚠️  HTTP $HTTP_CODE (재시도 $RETRY_COUNT/$MAX_RETRIES)"
                echo "응답: $BODY"
                if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                  sleep $((RETRY_COUNT * 3))
                fi
              fi
            done

            if [ "$SUCCESS" = "false" ]; then
              TOTAL_FAIL=$((TOTAL_FAIL + 1))
              echo "❌ 최종 실패 (재시도 모두 실패)"
            fi

            # 다음 호출까지 대기
            if [ $(date +%s) -lt $END_TIME ]; then
              echo "⏳ ${INTERVAL_SECONDS}초 대기 중..."
              sleep $INTERVAL_SECONDS
            fi
          done

          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          echo ""
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "📈 실행 요약"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "✅ 성공: $TOTAL_OK회"
          echo "❌ 실패: $TOTAL_FAIL회"
          if [ $TOTAL_KEYWORDS -gt 0 ]; then
            echo "📊 총 처리된 키워드: ${TOTAL_KEYWORDS}개"
          fi
          echo "⏱️  총 실행 시간: ${DURATION}초"
          echo "🎉 문서수 수집 작업 완료!"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
